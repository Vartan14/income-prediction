{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import numpy as np \n",
    "import pandas as pd  \n",
    "import seaborn as sns  \n",
    "%matplotlib inline\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ],
   "id": "d4e7be11c62d6d76"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##### 1. Bayesian Classification + Support Vector Machine",
   "id": "631a288eccae672a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Data\n",
    "analysis and data\n",
    "preparation"
   ],
   "id": "d81f10d5d8907888"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "df = pd.read_csv('adult.csv', header=None, sep=', ', engine='python')",
   "id": "5ca0e6c8a0a5401f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "df.head()",
   "id": "cfc45789e61f0050"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "df.columns = ['age', 'workclass', 'fnlwgt', 'education', 'education_num', 'marital_status', 'occupation',\n",
    "              'relationship',\n",
    "              'race', 'sex', 'capital_gain', 'capital_loss', 'hours_per_week', 'native_country', 'income']\n",
    "\n",
    "df.head()"
   ],
   "id": "394f1e6fa86e365f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "df.info()",
   "id": "1fde2346b6586169"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# find categorical variables\n",
    "\n",
    "categorical = list(df.select_dtypes(exclude='number').columns)\n",
    "print('The categorical variables are :\\n\\n', categorical)"
   ],
   "id": "a91330090ae3ba02"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "df[categorical].head()",
   "id": "68f7e9aad652f3e5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# view frequency counts of values in categorical variables\n",
    "\n",
    "for col in categorical:\n",
    "    print(df[col].value_counts(), '\\n')"
   ],
   "id": "1c04726ffa3cfe1f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# replace '?' values in workclass, occupation, native_country with `NaN`\n",
    "\n",
    "df['workclass'].replace('?', np.NaN, inplace=True)\n",
    "df['occupation'].replace('?', np.NaN, inplace=True)\n",
    "df['native_country'].replace('?', np.NaN, inplace=True)"
   ],
   "id": "7b83b8e13e2c7a2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "df[categorical].isnull().sum()",
   "id": "182f10415f969436"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "numerical = list(df.select_dtypes(include='number'))\n",
    "df[numerical].isnull().sum()"
   ],
   "id": "56ae6fe78f2908fb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Data\n",
    "splitting"
   ],
   "id": "a722970e181156f3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "X = df.drop(['income'], axis=1)\n",
    "y = df['income']"
   ],
   "id": "bb185eb9bb25df69"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)"
   ],
   "id": "7c559ec4cc748ee"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# impute missing categorical variables with most frequent value\n",
    "\n",
    "for df2 in [X_train, X_test]:\n",
    "    df2['workclass'].fillna(X_train['workclass'].mode()[0], inplace=True)\n",
    "    df2['occupation'].fillna(X_train['occupation'].mode()[0], inplace=True)\n",
    "    df2['native_country'].fillna(X_train['native_country'].mode()[0], inplace=True)"
   ],
   "id": "859510e02891b025"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# encode remaining variables with one-hot encoding\n",
    "import category_encoders as ce\n",
    "\n",
    "encoder = ce.OneHotEncoder(cols=['workclass', 'education', 'marital_status', 'occupation', 'relationship',\n",
    "                                 'race', 'sex', 'native_country'])\n",
    "\n",
    "X_train = encoder.fit_transform(X_train)\n",
    "\n",
    "X_test = encoder.transform(X_test)"
   ],
   "id": "5bcf408cced86a53"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "X_train.head()",
   "id": "9238cf9d5c4d712e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Feature\n",
    "scaling"
   ],
   "id": "c1f2ff1c5129de2a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "cols = X_train.columns\n",
    "scaler = RobustScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "X_train = pd.DataFrame(X_train, columns=[cols])\n",
    "X_test = pd.DataFrame(X_test, columns=[cols])"
   ],
   "id": "b5a4e98dda21ae66"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "X_train",
   "id": "2cab70a2e7489379"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Predict\n",
    "the\n",
    "results"
   ],
   "id": "b5fbbdf44db34a72"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# train a Gaussian Naive Bayes classifier on the training set\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "gnb_model = GaussianNB()\n",
    "gnb_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_gnb = gnb_model.predict(X_test)"
   ],
   "id": "a2eea49bc6ce6037"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# train a Support Vector classifier on the training set\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "svm_model = LinearSVC()\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_svm = svm_model.predict(X_test)"
   ],
   "id": "448e266377ce69ec"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Metrics",
   "id": "7ec34c5d21073c7a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from sklearn.metrics import recall_score, f1_score, accuracy_score\n",
    "\n",
    "\n",
    "def print_metrics(y_pred):\n",
    "    print('Accuracy score: {:.4f}'.format(accuracy_score(y_test, y_pred)))\n",
    "    print('Recall score: {:.4f}'.format(recall_score(y_test, y_pred, pos_label=\"<=50K\")))\n",
    "    print('F1 score: {:.4f}\\n'.format(f1_score(y_test, y_pred, pos_label=\"<=50K\")))\n",
    "\n",
    "\n",
    "print('Naive Bayes\\n')\n",
    "print_metrics(y_pred_gnb)\n",
    "\n",
    "print('Support Vector Machine\\n')\n",
    "print_metrics(y_pred_svm)"
   ],
   "id": "f25f55204cdca9ef"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Confusion\n",
    "matrix"
   ],
   "id": "5e94c974e0a4af2c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "def conf_matrix(y_pred):\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    cm_matrix = pd.DataFrame(data=cm, columns=['Actual Positive:1', 'Actual Negative:0'],\n",
    "                             index=['Predict Positive:1', 'Predict Negative:0'])\n",
    "    sns.heatmap(cm_matrix, annot=True, fmt='d', cmap='YlGnBu')\n",
    "\n",
    "\n",
    "print('Naive Bayes\\n')\n",
    "conf_matrix(y_pred_gnb)"
   ],
   "id": "ed3ac2889933d44"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "print('Support Vector Machine\\n')\n",
    "conf_matrix(y_pred_svm)"
   ],
   "id": "8a533432836f965a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Check\n",
    "for overfitting and underfitting"
   ],
   "id": "56f1939451ffa64a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def overfit_check(model):\n",
    "    print('Training set score: {:.4f}'.format(model.score(X_train, y_train)))\n",
    "    print('Test set score: {:.4f}\\n'.format(model.score(X_test, y_test)))\n",
    "    \n",
    "print('Naive Bayes\\n')\n",
    "overfit_check(gnb_model)\n",
    "\n",
    "print('Support Vector Machine\\n')\n",
    "overfit_check(svm_model)"
   ],
   "id": "f54b09c1d0d8cdcd"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "The\n",
    "training - set\n",
    "accuracy\n",
    "score and the\n",
    "test - set\n",
    "accuracy\n",
    "are\n",
    "quite\n",
    "comparable\n",
    "for both classifiers.So, there is no sign of overfitting."
   ],
   "id": "352a88e271405fa8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Null\n",
    "accuracy"
   ],
   "id": "c952024dd9e8967e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "y_test.value_counts()",
   "id": "4c247731d5f74fd6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "null_accuracy = (7407 / (7407 + 2362))\n",
    "\n",
    "print('Null accuracy score: {0:0.4f}'.format(null_accuracy))"
   ],
   "id": "6f3fbd36cdb2d19c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "We\n",
    "can\n",
    "see\n",
    "that\n",
    "our\n",
    "model\n",
    "accuracy\n",
    "score is 0.8083 / 0.8316\n",
    "but\n",
    "null\n",
    "accuracy\n",
    "score is 0.7582.So, we\n",
    "can\n",
    "conclude\n",
    "that\n",
    "our\n",
    "models\n",
    "are\n",
    "doing\n",
    "a\n",
    "very\n",
    "good\n",
    "job in predicting\n",
    "the class labels."
   ],
   "id": "f3aa4955fe612dc0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Conclusion",
   "id": "9938edd624b313ea"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "So, it\n",
    "seems\n",
    "that\n",
    "the\n",
    "Support\n",
    "Vector\n",
    "Machine(SVM)\n",
    "classifier\n",
    "outperforms\n",
    "the\n",
    "Naive\n",
    "Bayes\n",
    "classifier in terms\n",
    "of\n",
    "both\n",
    "accuracy and the\n",
    "ability\n",
    "to\n",
    "correctly\n",
    "classify\n",
    "positive\n",
    "instances(higher\n",
    "recall)."
   ],
   "id": "72fbd3769fc88971"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
